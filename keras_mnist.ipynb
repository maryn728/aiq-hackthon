{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/maryn728/aiq-hackthon/blob/master/keras_mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "NerKaPqo5-qU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras\n",
        "\n",
        "Keras is a **deep-learning framework** for Python that provides a** convenient way to define and**\n",
        "**train** almost any kind of deep-learning model.\n",
        "\n",
        "*   Same code can run seamlessly on **CPU** or **GPU**.\n",
        "*  ** User-friendly API** for quickly prototyping deep-learning models\n",
        "*   Built-in support for **convolutional networks** (for computer vision), **recurrent**\n",
        "**networks** (for sequence processing), and why not both.\n",
        "*   It supports** arbitrary network architectures**: multi-input or multi-output models,\n",
        "layer sharing, model sharing, and so on\n"
      ]
    },
    {
      "metadata": {
        "id": "P0uFZzMg8HVe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Keras** is a model-level library, providing **high-level building blocks ** for developing\n",
        "deep-learning models. It** doesn’t handle low-level operations** such as tensor manipulation\n",
        "and differentiation.\n",
        "\n",
        "The three existing backend implementations are the **TensorFlow** backend, the **Theano** backend, and the **Microsoft Cognitive Toolkit (CNTK)** backend.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![deep-learning software and hardware stack](https://xjgzgg.db.files.1drv.com/y4mczN9je-_l_9iyvOnD1luluRRwgriREPnCcJSbbv61ASBztV43qh1JcOg2uXBeGQkO30DHKWTTVUravQM18bKlR38Iq-pgvVEtCtnTXNFWCY0Az4HiT9pq0Svw7eKRAH4MnuZKSYpglAcdP_62bZOsl3Wqtic0SPjbWMUYo0Bc5J-JLvESBvjtg12w9kNgJWbtI-wv5JxTwskyCGsv3cYdw?width=360&height=186&cropmode=none)\n",
        "\n",
        "The deep-learning software and hardware stack. Source: François Chollet, Deep Learning with Python"
      ]
    },
    {
      "metadata": {
        "id": "2Trj2RwhiL1W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## What is MNIST?\n",
        "\n",
        "MNIST dataset contains images of handwritten digits. It has **60,000 grayscale images** under the **training** set and **10,000 grayscale images** under the **test** set"
      ]
    },
    {
      "metadata": {
        "id": "fKm-wXkitN7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "a3edbf51-8810-4e00-ee65-e4bc28b2eb04"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "digit = train_images[4]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEo1JREFUeJzt3XtsU/X/x/FXWZ2jwDIY6yIavOAI\nU+EPI5eCMAYEHBG5aLhMmCTEQBTCJYQQZGDEcBmIYRLDxjVhMTZZCPIHcZMQhZAxZH8Qtz8cEEMW\nhLHB5CIDWeH3xze/Rlix75V2pxvPx1/fnX04fdfq83vaw+lxPXjw4IEAAP+pi9MDAEBHQCwBwIBY\nAoABsQQAA2IJAAbEEgAMiCUAGBBLADBwR/oH169frzNnzsjlcmnVqlUaNGhQNOcCgLgSUSxPnTql\nCxcuyO/36/z581q1apX8fn+0ZwOAuBHR2/CKigqNGzdOktSvXz9dv35dt27diupgABBPIoplY2Oj\nevbsGfy5V69eamhoiNpQABBvonKCh+/iANDZRRRLr9erxsbG4M9XrlxRWlpa1IYCgHgTUSxHjBih\nsrIySVJNTY28Xq+6d+8e1cEAIJ5EdDb8zTff1Ouvv66ZM2fK5XJp7dq10Z4LAOKKiy//BYDwuIIH\nAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGx\nBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBA\nLAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAY\nEEsAMCCWAGDgjuQPVVZWavHixcrIyJAk9e/fX/n5+VEdDADiSUSxlKQhQ4aosLAwmrMAQNzibTgA\nGEQcy3PnzmnBggWaNWuWTpw4Ec2ZACDuuB48ePCgrX+ovr5eVVVVysnJUV1dnfLy8lReXq7ExMRY\nzAgAjovoyDI9PV0TJ06Uy+VS37591bt3b9XX10d7NgCIGxHF8tChQ9q9e7ckqaGhQVevXlV6enpU\nBwOAeBLR2/Bbt25p+fLlunHjhu7du6eFCxcqKysrFvMBQFyIKJYA8LThrw4BgAGxBAADYgkABsQS\nAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABhHfVgKwqqysNK/dv3+/ad2xY8fM+6yurg65\n/f79++rSJbLjha+++sq8tk+fPua1x48fN6+dM2dOq21Dhw5t9c976NCh5n3i8TiyBAADYgkABsQS\nAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADruBBRPx+v3nt4sWLzWsbGhpM69pyU9LRo0ebf9fY\n2Gja5/Lly82P3xZteV6hZv3+++/19ddft9qGJ8eRJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkA\nBsQSAAyIJQAYEEsAMOByx6dAS0uLee2vv/4acrvP51NFRUXw548//ti8z7///tu8Nisry7QuPz/f\nvM+33377sb8rKyt76Oe7d++a9jl9+nTz4z/6GNHy1ltvtWk7ngxHlgBgQCwBwIBYAoABsQQAA2IJ\nAAbEEgAMiCUAGBBLADAglgBgQCwBwMD1oC23k0OHtG/fPvPaefPmhdweCASUkJAQ0eOPHz/evNZ6\n18jk5OSIZgmnpKTEtO6jjz6KyeO/8MIL5rWnT59utS0tLa3VHTLT0tKeeC4Yjyxra2s1bty44L9I\nly5d0pw5c5Sbm6vFixfrn3/+iemQAOC0sLG8ffu21q1bJ5/PF9xWWFio3Nxcfffdd3rxxRdVWloa\n0yEBwGlhY5mYmKidO3fK6/UGt1VWVmrs2LGSpOzs7Ie+jQYAOqOwX9Hmdrvldj+8rLm5WYmJiZKk\n1NTUVp+RAEBn88TfZ8n5ofg3d+7cqKwNBAJPPkycmz17dlTXOYETOrERUSw9Ho/u3LmjpKQk1dfX\nP/QWHfGHs+F2nA3H40T09yyHDx8e/Pbn8vJyjRw5MqpDAUC8CXtkWV1drU2bNunixYtyu90qKyvT\nli1btHLlSvn9fvXp00dTpkxpj1kBwDFhY/nGG29o//79rbbv3bs3JgMBQDziCp4OavXq1ea169ev\nN691uVwhtz/6meWnn35q3ueXX35pXhurzyKtMjMzTetqa2tj8vgHDhwwr508eXJMZkBoXBsOAAbE\nEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMnvj7LBFdX3zxhWldWy5hfPbZZ81r\nJ0yY8NjfTZo0Kfi/N23aZN5n165dzWut7ty5Y15bXl4ecvt7772nQ4cOPbTtwoULpn225Srh/Px8\n81ouYYxfHFkCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAAD7u7YDv766y/z\n2gEDBpjWNTQ0mPf578sUwzl48KB5bSycO3fOtO7DDz807/P06dMhtz96x8q2+OCDD8xr9+zZY17b\nrVu3SMZBO+DIEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMuIKnHVy5csW89rnn\nnov64//xxx/mtUlJSSG3e73eh57H3r17zfv84YcfzGtrampM627evGnep8vlCrk91BU8XbrYjh8O\nHDhgfvy2XEGF+MWRJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMOByx3bQ\nlhuWZWZmmta15RLKtrzEbbk0MBaef/5507q2PKc///wz5PZQz8nr9Zr2eenSJfPjo3PgyBIADEyx\nrK2t1bhx41RSUiJJWrlypSZNmqQ5c+Zozpw5+vnnn2M5IwA4zh1uwe3bt7Vu3Tr5fL6Hti9btkzZ\n2dkxGwwA4knYI8vExETt3LnT/FkOAHRGYY8s3W633O7Wy0pKSrR3716lpqYqPz9fvXr1ismAnUFK\nSop5bTyfOAgEAk6PEHWd8TkhNsLGMpTJkycrJSVFmZmZKi4u1vbt27VmzZpoz9ZpcDbcjrPhiFcR\nnQ33+XzB/6jHjBmj2traqA4FAPEmolguWrRIdXV1kqTKykplZGREdSgAiDdh34ZXV1dr06ZNunjx\notxut8rKyjR79mwtWbJEXbt2lcfj0YYNG9pjVgBwDFfwtAM+s7TjM0vEq4hO8KBt2nI2/ODBg6Z1\n7777rnmfV69eNa999dVXTb+bPHmyeZ9z5841r7X+rYqZM2ea9/m4WD7pfvF04XJHADAglgBgQCwB\nwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgwOWOcWbo0KGmdQ0NDTGepLXff/895o9x7Ngx\n07pffvnFvM/HXe8utb7G/JVXXjHvF08XjiwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBg\nQCwBwIAreBBXmpubTev+66qctqx99HfcsAyPw5ElABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAG\nxBIADIglABgQSwAwcD149I5NQAfQpYv9/+cfd7ljIBBQQkLCQ9suX75s2mdaWpr58dE5cGQJAAbE\nEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMuLsj4kpZWZnTIwAhmWJZUFCgqqoq\ntbS0aP78+Ro4cKBWrFihQCCgtLQ0bd68WYmJibGeFQAcEzaWJ0+e1NmzZ+X3+9XU1KSpU6fK5/Mp\nNzdXOTk52rp1q0pLS5Wbm9se8wKAI8J+Zjl48GBt27ZNkpScnKzm5mZVVlZq7NixkqTs7GxVVFTE\ndkoAcFjYWCYkJMjj8UiSSktLNWrUKDU3NwffdqempqqhoSG2UwKAw8wneI4cOaLS0lLt2bNH48eP\nD27n6zARTRMmTDCtu3//flQeLxAIRGU/6PxMsTx+/Lh27NihXbt2qUePHvJ4PLpz546SkpJUX18v\nr9cb6znxlLCeDc/JyTHvky//RTSEfRt+8+ZNFRQUqKioSCkpKZKk4cOHB/+lLi8v18iRI2M7JQA4\nLOyR5eHDh9XU1KQlS5YEt23cuFGrV6+W3+9Xnz59NGXKlJgOCQBO4x48iCu8DUe84goexJXz5887\nPQIQEteGA4ABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAAy53RFyxfoNVtL7S\ngK9GgBVHlgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIDLHRFXBg4caFqX\nkZFh3ud/3THy0dvkWu8uya1wnz4cWQKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKA\ngesBd2xCB7Rv3z7z2nnz5oXcHggElJCQ8NC2rKws0z63b99ufvzXXnvNvBbxiyNLADAglgBgQCwB\nwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgwOWO6JBu3LhhXjt9+vSQ23/88Ue98847D237\n6aefTPt8//33zY+/d+9e89pu3bqZ16J9me7uWFBQoKqqKrW0tGj+/Pk6evSoampqlJKSIul/196O\nHj06lnMCgKPCxvLkyZM6e/as/H6/mpqaNHXqVA0bNkzLli1TdnZ2e8wIAI4LG8vBgwdr0KBBkqTk\n5GQ1NzcrEAjEfDAAiCdhT/AkJCTI4/FIkkpLSzVq1CglJCSopKREeXl5Wrp0qa5duxbzQQHASeYT\nPEeOHFFRUZH27Nmj6upqpaSkKDMzU8XFxbp8+bLWrFkT61kBwDGmEzzHjx/Xjh07tGvXLvXo0UM+\nny/4uzFjxujzzz+P1XxASJwNR3sL+zb85s2bKigoUFFRUfDs96JFi1RXVydJqqysVEZGRmynBACH\nhT2yPHz4sJqamrRkyZLgtmnTpmnJkiXq2rWrPB6PNmzYENMhAcBpYWM5Y8YMzZgxo9X2qVOnxmQg\nAIhHXO4IAAZc7ohO73Eng5KTk1v97rPPPjPt89tvvzU//m+//WZey50g4xdHlgBgQCwBwIBYAoAB\nsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgwBU8AGDAkSUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJ\nAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGLideND169frzJkzcrlc\nWrVqlQYNGuTEGFFVWVmpxYsXKyMjQ5LUv39/5efnOzxV5Gpra/XJJ59o7ty5mj17ti5duqQVK1Yo\nEAgoLS1NmzdvVmJiotNjtsmjz2nlypWqqalRSkqKJGnevHkaPXq0s0O2UUFBgaqqqtTS0qL58+dr\n4MCBHf51klo/r6NHjzr+WrV7LE+dOqULFy7I7/fr/PnzWrVqlfx+f3uPERNDhgxRYWGh02M8sdu3\nb2vdunXy+XzBbYWFhcrNzVVOTo62bt2q0tJS5ebmOjhl24R6TpK0bNkyZWdnOzTVkzl58qTOnj0r\nv9+vpqYmTZ06VT6fr0O/TlLo5zVs2DDHX6t2fxteUVGhcePGSZL69eun69ev69atW+09Bv5DYmKi\ndu7cKa/XG9xWWVmpsWPHSpKys7NVUVHh1HgRCfWcOrrBgwdr27ZtkqTk5GQ1Nzd3+NdJCv28AoGA\nw1M5EMvGxkb17Nkz+HOvXr3U0NDQ3mPExLlz57RgwQLNmjVLJ06ccHqciLndbiUlJT20rbm5Ofh2\nLjU1tcO9ZqGekySVlJQoLy9PS5cu1bVr1xyYLHIJCQnyeDySpNLSUo0aNarDv05S6OeVkJDg+Gvl\nyGeW/9ZZbi750ksvaeHChcrJyVFdXZ3y8vJUXl7eIT8vCqezvGaTJ09WSkqKMjMzVVxcrO3bt2vN\nmjVOj9VmR44cUWlpqfbs2aPx48cHt3f01+nfz6u6utrx16rdjyy9Xq8aGxuDP1+5ckVpaWntPUbU\npaena+LEiXK5XOrbt6969+6t+vp6p8eKGo/Hozt37kiS6uvrO8XbWZ/Pp8zMTEnSmDFjVFtb6/BE\nbXf8+HHt2LFDO3fuVI8ePTrN6/To84qH16rdYzlixAiVlZVJkmpqauT1etW9e/f2HiPqDh06pN27\nd0uSGhoadPXqVaWnpzs8VfQMHz48+LqVl5dr5MiRDk/05BYtWqS6ujpJ//tM9v//JkNHcfPmTRUU\nFKioqCh4lrgzvE6hnlc8vFauBw4cq2/ZskWnT5+Wy+XS2rVrNWDAgPYeIepu3bql5cuX68aNG7p3\n754WLlyorKwsp8eKSHV1tTZt2qSLFy/K7XYrPT1dW7Zs0cqVK3X37l316dNHGzZs0DPPPOP0qGah\nntPs2bNVXFysrl27yuPxaMOGDUpNTXV6VDO/369vvvlGL7/8cnDbxo0btXr16g77Okmhn9e0adNU\nUlLi6GvlSCwBoKPhCh4AMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAY/B/mpEhCeoCgjgAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fccbf60b208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SnvHPv7gIHpK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **typical Keras workflow** has the following steps:\n",
        "\n",
        "1.   Define your **training data**: input tensors and target tensors.\n",
        "2.   Define a **network of layers** (or model) that maps your inputs to your targets.\n",
        "3.   Configure the learning process by **choosing a loss function, an optimizer, and**\n",
        "**some metrics to monitor**.\n",
        "4.   Iterate on your training data by **calling the fit()** method of your model."
      ]
    },
    {
      "metadata": {
        "id": "1wat7SP8tVEO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wHgV_yG9tyb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e039b2af-9ff7-4ca5-a6ec-6255be39b7e1"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KfmiBTNvKFzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training images for instance were stored in an array of shape` (60000, 28, 28)` of type uint8 with values in the `[0, 255]` interval. We transform it into a float32 array of shape `(60000, 28 * 28)` with values between 0 and 1."
      ]
    },
    {
      "metadata": {
        "id": "JF6UsROQt1Jf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JUQvffHDuAxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "0b9c0b72-3a2c-492c-9d6c-85de6fa93717"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Md01T-muL37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a2bfc5eb-15db-4d51-e2fb-8c53fa8c9825"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2724 - acc: 0.9220\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1082 - acc: 0.9684\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0718 - acc: 0.9792\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.0496 - acc: 0.9858\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.0380 - acc: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc7bd97240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "et9qAV4iuZjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "83e87151-0026-4c53-e7cd-b5769e184b5c"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 68us/step\n",
            "test_acc: 0.9789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AM5rHDQzMvEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "599e9ef5-71c3-46da-9e8a-e4e2ce51bae5"
      },
      "cell_type": "code",
      "source": [
        "sample_image = test_images[0].reshape(1,28 * 28)\n",
        "y_prob = model.predict(sample_image)[0]\n",
        "y_pred = y_prob.argmax()\n",
        "y_actual = test_labels[0].argmax()\n",
        "\n",
        "print(\"probabilities: \", y_prob)\n",
        "print(\"predicted = %d, actual = %d\" % (y_pred, y_actual))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "probabilities:  [2.4786220e-07 1.8203666e-08 3.0202020e-04 8.8411802e-04 2.2671200e-09\n",
            " 3.7955857e-07 1.1797386e-09 9.9876010e-01 3.3412737e-06 4.9735740e-05]\n",
            "predicted = 7, actual = 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ssRV91mdLVvG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check out the official [Keras Docs](https://keras.io/) for more details\n",
        "\n",
        "For even more examples see [here](https://github.com/fchollet/deep-learning-with-python-notebooks) for more Keras examples - Deep Learning with Python code samples, as Jupyter notebooks\n",
        "\n",
        "Some cool cheatsheets:\n",
        "\n",
        "\n",
        "*   [Keras](http://datacamp-community.s3.amazonaws.com/94fc681d-5422-40cb-a129-2218e9522f17)\n",
        "*   [Numpy](http://datacamp-community.s3.amazonaws.com/e9f83f72-a81b-42c7-af44-4e35b48b20b7)\n",
        "*   [Scikit-Learn](http://datacamp-community.s3.amazonaws.com/5433fa18-9f43-44cc-b228-74672efcd116)\n",
        "*   [Matplotlib](http://datacamp-community.s3.amazonaws.com/28b8210c-60cc-4f13-b0b4-5b4f2ad4790b)\n",
        "*   [SciPy](http://datacamp-community.s3.amazonaws.com/5710caa7-94d4-4248-be94-d23dea9e668f)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}